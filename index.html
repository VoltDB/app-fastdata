<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>App-fastdata by VoltDB</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>App-fastdata</h1>
        <p></p>

        <p class="view"><a href="https://github.com/VoltDB/app-fastdata">View the Project on GitHub <small>VoltDB/app-fastdata</small></a></p>


        <ul>
          <li><a href="https://github.com/VoltDB/app-fastdata/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/VoltDB/app-fastdata/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/VoltDB/app-fastdata">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="voltdb-fast-data-example-app" class="anchor" href="#voltdb-fast-data-example-app" aria-hidden="true"><span class="octicon octicon-link"></span></a>VoltDB Fast Data Example App</h1>

<h2>
<a id="use-case" class="anchor" href="#use-case" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use Case</h2>

<p>The Fast Data app simulates real-time click stream processing. Click events are
ingested into VoltDB at a high rate, then cleaned up and persisted into a data
warehouse for historical analysis. Segmentation information is calculated in
data warehouse and stored back into VoltDB. VoltDB uses the information to
segment real-time events for per-event decisioning.</p>

<p>The click events can come from persistent queues like <a href="http://kafka.apache.org">Apache
Kafka</a>. For simplicity, this sample app generates
random events at a constant rate. Each click event contains basic information
like source IP address, destination URL, timestamp, HTTP method name, referral
URL, and the user agent string. More information can be included in a real-world
use case.</p>

<p>The stream is ingested into VoltDB, cleaned up, then exported into a data
warehouse like <a href="http://hadoop.apache.org">Hadoop</a> for long term persistence. The
data warehouse runs machine learning algorithm on the full historical dataset to
segment the click events into clusters periodically. Each cluster is represented
by its center. The cluster centers are sent back into VoltDB.</p>

<p>VoltDB uses the clustering information to further segment new click events into
the corresponding cluster at real-time. VoltDB can use this to make per-event
real-time decisions like what advertisement to show a user, or whether a user
should be blocked for spamming.</p>

<p>Events are aged out of VoltDB after they are persisted in the data
warehouse. This limits the dataset inside VoltDB to only include relatively hot
data.</p>

<p>The example includes a dashboard that shows click stream cluster distribution,
top users and top visited URLs in a moving window. All of these information is
calculated from materialized views on relevant source tables.</p>

<h2>
<a id="code-organization" class="anchor" href="#code-organization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code organization</h2>

<p>The code is divided into projects:</p>

<ul>
<li>"db": the database project, which contains the schema, stored procedures and
other configurations that are compiled into a catalog and run in a VoltDB
database.</li>
<li>"client": a java client that generates click events.</li>
<li>"web": a simple web server that provides the demo dashboard.</li>
<li>"hadoop": a collection of pig/shell scripts, and a Spark program</li>
</ul>

<p>See below for instructions on running these applications.  For any questions,
please contact <a href="mailto:fieldengineering@voltdb.com">fieldengineering@voltdb.com</a>.</p>

<h2>
<a id="pre-requisites" class="anchor" href="#pre-requisites" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pre-requisites</h2>

<ol>
<li>
<p>Before running these scripts you need to have VoltDB 4.8 or later installed,
and the bin subdirectory should be added to your PATH environment variable.
For example, if you installed VoltDB Enterprise 4.8 in your home directory,
you could add it to the PATH with the following command:</p>

<div class="highlight highlight-bash"><pre><span class="pl-s">export</span> PATH=<span class="pl-s1"><span class="pl-pds">"</span><span class="pl-vo">$PATH</span>:<span class="pl-vo">$HOME</span>/voltdb-ent-4.8/bin<span class="pl-pds">"</span></span></pre></div>
</li>
</ol>

<h2>
<a id="hadoop-demo" class="anchor" href="#hadoop-demo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hadoop Demo</h2>

<p>This demo requires a <a href="http://www.cloudera.com/content/cloudera/en/downloads/cloudera_manager/cm-5-2-1.html">Cloudera</a>
Hadoop installation, whose configured services also include <a href="https://spark.apache.org/">Spark</a>.
The demo consists of a VoltDB server writing export data to files stored in Hadoop, and
a set of scripts, and programs that collect the exported data, compute k-means clusters on the
collected data, and store the computations back to VoltDB.</p>

<ol>
<li>
<p>On the server where VoltDB is installed set the environment variable
<code>WEBHDFS_ENDPOINT</code> to a WebHDFS endpoint that matches the following pattern</p>

<pre><code>http://[host]:[port]/webhdfs/v1/[export-base-directory]/%g/%p/%t.avro?user.name=[user]
</code></pre>
</li>
<li>
<p>Download this <a href="http://downloads.voltdb.com/technologies/other/fastdata-kmeans.tar.bz2">archive</a>
and unpack it on an Hadoop node</p>

<div class="highlight highlight-bash"><pre>$ tar -jxf fastdata-kmeans.tar.bz2</pre></div>
</li>
<li>
<p>Change your working directory to <code>fastdata-kmeans</code> and run the <code>compute_clusters.sh</code>
script when you to want to process exported data from VoltDB (see 
<a href="#demo-instructions"><strong>Demo Instructions</strong></a> section bellow)</p>

<div class="highlight highlight-bash"><pre>$ <span class="pl-s3">cd</span> fastdata-kmeans
<span class="pl-c">#</span>
<span class="pl-c"># Assuming you are exporting to export/fastdata, and VoltDB is</span>
<span class="pl-c"># running on volthost</span>
$ ./compute_clusters.sh <span class="pl-s">export</span>/fastdata volthost</pre></div>

<p>This script</p>

<ul>
<li>Harvests the exported data by renaming the export base directory</li>
<li>Invokes the <code>harvest.pig</code> pig script to write the harvested data into a
Parquet database</li>
<li>Starts a Spark job that computes the K-Means clusters on the data stored
in the parquet database, and creates another parquet db with the resulting
computations.</li>
<li>Invokes the <code>load.pig</code> script that reads the K-Means computation Parquet
database, and writes its content back to VoltDB by utilizing the
<a href="https://github.com/VoltDB/voltdb-hadoop-extension">VoltDB hadoop extensions</a>
</li>
</ul>
</li>
</ol>

<h2>
<a id="vertica-demo" class="anchor" href="#vertica-demo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Vertica Demo</h2>

<ol>
<li>
<p>This example also requires <a href="http://www.vertica.com">Vertica</a> installed on the
same machine or a machine that the VoltDB machine has access to. A Vertica
database must be created with the username <strong>dbadmin</strong> with no password. Once
Vertica is running, set the environment variable <code>VERTICAIP</code> to point to the
Vertica machine on the VoltDB machine. For example, if your Vertica is
running on 192.168.0.1, run the following command on the VoltDB machine:</p>

<div class="highlight highlight-bash"><pre><span class="pl-s">export</span> VERTICAIP=<span class="pl-s1"><span class="pl-pds">"</span>192.168.0.1<span class="pl-pds">"</span></span></pre></div>
</li>
<li><p>VoltDB uses JDBC to export click events to Vertica. Vertica's JDBC driver
must be present in the classpath before starting VoltDB. If your Vertica is
installed in <code>/opt/vertica</code>, you can find the JDBC driver in
<code>/opt/vertica/java/lib/</code>. Copy the JAR file in that directory to the VoltDB
machine and put it in the <code>lib/extension</code> sub-directory in your VoltDB
installation.</p></li>
<li><p>To run the K-means clustering algorithm in Vertica, it requires the R
language package to be installed. Please follow the instructions in <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/ProgrammersGuide/UserDefinedFunctions/UDxR/InstallingRForHPVertica.htm">Vertica
documentation</a>
to install the R language pack.</p></li>
<li><p>Copy the <code>vertica</code> sub-directory in the example to the vertica machine. This
directory contains Vertica extensions for K-means clustering and loading data
back into VoltDB. The following instructions assume that the directory is
copied to <code>/tmp/vertica</code>.</p></li>
</ol>

<h2>
<a id="demo-instructions" class="anchor" href="#demo-instructions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Demo Instructions</h2>

<ol>
<li>
<p>Start the web server</p>

<div class="highlight highlight-bash"><pre>./run.sh start_web</pre></div>
</li>
<li>
<p>Start the database and client</p>

<div class="highlight highlight-bash"><pre><span class="pl-c"># for Hadoop run</span>
$ ./run.sh hadoop_demo
<span class="pl-c"># while for Vertical run</span>
$ ./run.sh demo</pre></div>
</li>
<li><p>Open a web browser to http://hostname:8081</p></li>
<li>
<p>For Vertica run the <code>updatemodel.sh</code> script on the Vertica machine to run
the K-means clustering algorithm on the data in Vertica. You can run this
command periodically to update the cluster model in VoltDB.</p>

<div class="highlight highlight-bash"><pre>$ /tmp/vertica/updatemodel.sh</pre></div>
</li>
<li><p>To stop the demo:</p></li>
</ol>

<p>Stop the client (if it hasn't already completed) by pressing Ctrl-C</p>

<p>Stop the database</p>

<div class="highlight highlight-bash"><pre>$ voltadmin shutdown</pre></div>

<p>Stop the web server</p>

<div class="highlight highlight-bash"><pre>$ ./run.sh stop_web</pre></div>

<h2>
<a id="options" class="anchor" href="#options" aria-hidden="true"><span class="octicon octicon-link"></span></a>Options</h2>

<p>You can control various characteristics of the demo by modifying the parameters
passed into the LogGenerator java application in the "client" function within
the run.sh script.</p>

<p>Speed &amp; Duration:</p>

<pre><code>--duration=120                (benchmark duration in seconds)
--ratelimit=20000             (run up to this rate of requests/second)
</code></pre>

<h2>
<a id="instructions-for-running-on-a-cluster" class="anchor" href="#instructions-for-running-on-a-cluster" aria-hidden="true"><span class="octicon octicon-link"></span></a>Instructions for running on a cluster</h2>

<p>Before running this demo on a cluster, make the following changes:</p>

<ol>
<li>
<p>On each server, edit the run.sh file to set the HOST variable to the name of
the <strong>first</strong> server in the cluster:</p>

<p>HOST=voltserver01</p>
</li>
<li>
<p>On each server, edit db/deployment.xml to change hostcount from 1 to the
actual number of servers:</p>

<pre><code>&lt;cluster hostcount="1" sitesperhost="3" kfactor="0" /&gt;
</code></pre>
</li>
<li>
<p>On each server, start the database</p>

<div class="highlight highlight-bash"><pre>./run.sh server</pre></div>
</li>
<li>
<p>On one server, Edit the run.sh script to set the SERVERS variable to a
comma-separated list of the servers in the cluster</p>

<p>SERVERS=voltserver01,voltserver02,voltserver03</p>
</li>
<li>
<p>Run the client script:</p>

<div class="highlight highlight-bash"><pre>./run.sh client</pre></div>
</li>
</ol>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/VoltDB">VoltDB</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-130533-10");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>